---
layout: post
title: Interpretability in Machine Learning and Generalized Additive Models
---

These days, I come a across a lot of blog posts describing the power and capabilities of Machine Learning (ML) and how [Artificial Intelligence (AI)](www.economist.com/futureofwork) will shape the future of humankind. Most of this press can be attributed to the renewed interest in Neural Networks, specifically [Deep Learning](http://www.wired.com/tag/deep-learning/), which is a technique that aspires to solve problems, that have until now been exclusively reserved for humans. Examples comprise areas such as autonomous driving, image recognition, instantaneous interpetation, voice recognition and many more [^fn-references].

With ML taking over human capabilities, new questions arise around why an algorithm chose a certain outcome. I.e. interpretability becomes a necessities for implementing policies and create accountability. A classic, though admittetly somewhat contrived, example is the choice problem of self-driving car that has to decide whether it kills a pedestrian waling into the street or steering the car off the road and killing its driver. To assess what went wrong and discuss consequences, we need to understand the decision making process of an algorithm. This is what is meant by *interpretable* machine learning algorithms.

# Interpretability vs. performance

Typically there is a trade-off between interpretability of a ML algorithm and its power. Interpretable models are using very few hand-selected features and a given functional form, such as a linear or logistic regression. Consequently these models have a limited capacity to learn interactions and dependencies between the features. This is summarized by the [VC dimension](https://en.wikipedia.org/wiki/VC_dimension) that gives us a measure of the expressive power of a class of learning algorithms. On the other end of the spectrum are algorithms such as Neural Networks and Random Forests that posses a high VC dimension, but are typically not easy to interpret.

|Algorithm         | Intelligibility | Accuracy | VC dimension | 
|------------------|:---------------:|:--------:|:------------:|
|Linear Classifier[^fn-linClassEx] | +++             | +        | d+1          |
| Random Forest  | + | ++ | |
| Neural Network  | - | +++ | [$$O(\rho^2)$$](http://www.mit.edu/~esontag/FTP_DIR/vc-expo.pdf), $$\rho$$: num. of weights |

This raises the question if there is a class of models that can combine the benefits of intelligibility and performance, or at least find an acceptable tradeoff between these criteria. The reason for this is nicely summarized in the paper of [Caruana et al.](http://doi.acm.org/10.1145/2783258.2788613):

>Applying any of these [avdanced, unintelligible] methods to mission-critical problems such as healthcare remains problematic, in part because usually it is not ethical to modify (or randomize) the care delivered to patients to collect data sets that will not suffer from the kinds of bias described above. Learning must be done with the data that is available, not the data one would want. But it is critical that models trained on real-world data be validated prior to use lest some patients be put at risk, which makes using the most accurate learning methods challenging.

The validation referenced in this quote can be interpreted in a way that a domain expert should be in the position of assessing why a model reached a certain decision and whether this decision is sound, given the data. Most often this involves some visual inspection of the model. However, humans are intriniscally limited in their visualization capabilities; with two-dimensional plot really being the edge of our capacity.

This limitation can guide us in the construction of intelligble models: Try to avoid high-dimensional feature interactions,but try to keep the non-linearities within a given feature! This is exactly what a Generalized Additive Model (GAM) is trying to achieve.

# GAMs a.k.a. Generalized Additive Models

[GAM](https://en.wikipedia.org/wiki/Generalized_additive_model)s are not a new technique, but have been introduced by [Hastie and Tibshirani](https://web.stanford.edu/~hastie/Papers/gam.pdf) already in 1986. They can be considered as a generalization of lineare model such as Logistic Regressions. Consider a data set with $$n$$ records $$x_i$$ with $$p$$ features (dimensions) and a target variable $$y$$. Then the functional form of a GAM is given by

$$
\begin{align}
g(\hat y) \, = \, f_1(x_1) + f_2(x_2) + \dots + f_p(x_p) \,=\, \sum_{i=1}^{p} f_i(x_i)
\end{align}
$$

The function $$g(\hat y)$$ is called the *link function* and is chosen according to the modeling problem at hand. For a regression problem is is just the identity function. For a classification problem $$\hat y$$ will turn into a probability estimate and the link function is chosen as the log-odds function

$$
\begin{align}
\hat y \rightarrow p(y=1 \vert x) \\
g(\hat y) \rightarrow \log\frac{p}{1-p}.
\end{align}
$$

The functions $$f_i$$ are the *shape function* associated with the $$i$$-th feature (dimension) and need to be learned. The shape functions incorporate all the nonlinearities of the algorithm and are in general non-parametric. To see that these functions do contain non-linearities we can make use of a [Taylor expansion](https://en.wikipedia.org/wiki/Taylor_series)[^fn-TaylorExpansion]

$$
\begin{align}
f(x) = f(0) + f'(0) x + \frac{f''(0)}{2} x^2 + \frac{f'''(0)}{6} x^3 + \dots
\end{align}
$$

We see that the shape functions can introduce arbitrary interactions of a single feature with itself. Moreover, the GAM reduces to a simple Logit if we regularize the quadratic and higher order terms and in this sense generalizes the Logit and other linear models.

This is all nice and well, but give me some intuition and understanding of this!

# Optimization in Function Space

## Objective

## Gradient Boosting as a potential optimizer



[^fn-references]: There are far too many examples in each category so that I refrain from giving references here. If you have a good summary link that gives an overview for any of these fields, I would be happy to include it here and share it with the rest of the world.

[^fn-linClassEx]: These include algorithms such as Linear and Logistic Regression.

[^fn-TaylorExpansion]: We limit ourselves here to $$x_0 = 0$$ as the point we expand around. But this can be generalized arbitrarily.
